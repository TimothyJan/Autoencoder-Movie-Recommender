{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 5 - Autoencoder Movie Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimothyJan/Autoencoder-Movie-Recommender/blob/main/Autoencoder_Movie_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Project 5 - Recommendation with Autoencoders</h1>\n",
        "<p>CPSC 585<br>\n",
        "Spring 2022<br>\n",
        "Section 13883<br></p>\n",
        "\n",
        "Sean Javiya<br>\n",
        "Timothy Jan<br>\n",
        "Timothy Kheang<br>\n",
        "\n",
        "In Project 5, we apply autoencoders to the task of making movie recommendations.\n",
        "\n",
        "Goals for this project are:\n",
        "<ul>\n",
        "  <li>Examining how autoencoders can be used for recommendation.</li>\n",
        "  <li>Understanding the connection between autoencoders and embedding.</li>\n",
        "  <li>Implementing basic, deep, and variational autoencoders.</li>\n",
        "  <li>Evaluating recommender performance.</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "9V2TJ-DOiVzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 1</h1>\n",
        "<p>We began with the Keras example <a href=\"https://keras.io/examples/structured_data/collaborative_filtering_movielens/\">Collaborative Filtering for Movie Recommendations</a>.</p>\n",
        "\n",
        "<p>This example demonstrates <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">Collaborative filtering</a> using the <a href=\"https://www.kaggle.com/c/movielens-100k\">Movielens dataset</a> to recommend movies to users. The MovieLens ratings dataset lists the ratings given by a set of users to a set of movies. Our goal is to be able to predict ratings for movies a user has not yet watched. The movies with the highest predicted ratings can then be recommended to the user.</p>\n",
        "\n",
        "<p>First we download the <a href=https://www.kaggle.com/c/movielens-100k>Movielens</a> dataset, extract it, and save the CSV into <code>ratings_file</code>. It is then read into a Pandas Dataframe <code>df</code> with <code>pd.read_csv</code>.</p>"
      ],
      "metadata": {
        "id": "VvPj5B-Xi7oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LwHPiMxXgrzX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "# Use the ratings.csv file\n",
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "id": "ng1PiosHj208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a826720a-fab5-454c-a245-c71e31d0ae34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "983040/978202 [==============================] - 0s 0us/step\n",
            "991232/978202 [==============================] - 0s 0us/step\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Next, we do some preprocessing to encode users and movies as integer indices. We take the <code>df</code> columns <code>userId</code> and <code>movieId</code>, encode them, and save them into two new columns <code>user</code> and <code>movie</code>. <code>min_rating</code> and <code>max_rating</code> will be used to normalize the ratings later.</p>"
      ],
      "metadata": {
        "id": "zbRv2Tm4kJ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y3U0k_jkHa1",
        "outputId": "ac5afff6-ddc0-409d-cc25-ded0ae72bad2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We then prepare the training and validation data by using <code>\"user\"</code>, <code>\"movie\"</code>, <code>min_rating</code> and <code>max_rating</code>. The data is split so that 90% of the data is used for training and 10% is used for validation.</p>"
      ],
      "metadata": {
        "id": "9A1Vnf1WkShb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "metadata": {
        "id": "nyoZvZqGkQgI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we create the model. We embed both users and movies into 50-dimensional vectors.</p>\n",
        "\n",
        "<p>The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias. The match score is scaled to the [0, 1] interval via a sigmoid (since our ratings are normalized to this range).</p>\n",
        "\n",
        "<p>We are using an <code>Embedding</code> layer instead of a single <code>Dense</code> hidden layer because <code>Embedding</code> layers work well with sparse data (e.g. where users have not rated most movies in the dataset).</p>"
      ],
      "metadata": {
        "id": "_101bbDMkdnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "first_model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "first_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4cP5EUokXGf",
        "outputId": "7fbab4b3-b92e-4621-8431-8c4fab65820d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we fit the model to our dataset. We used a batch size of 64, 5 epochs, and a verbosity of 1 to visualize <code>loss</code> and <code>val_loss</code>. After training, we achieve a <code>loss</code> of 0.6071 and a <code>val_loss</code> of 0.6129.</p>"
      ],
      "metadata": {
        "id": "VXnLbaMSktox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = first_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI44E4LSkcVo",
        "outputId": "bdb94263-753a-4db2-fe6e-709b97c86f4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 15s 5ms/step - loss: 0.6361 - val_loss: 0.6207\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 7s 5ms/step - loss: 0.6135 - val_loss: 0.6209\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.6089 - val_loss: 0.6142\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.6080 - val_loss: 0.6147\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 4s 3ms/step - loss: 0.6073 - val_loss: 0.6137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We plot the training and validation loss to visualize the training process.</p>"
      ],
      "metadata": {
        "id": "PY14I6Jvk10A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4GECJpdskzxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "2d440504-660b-4dab-976c-5cde7c141ae1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnMpOVhJAFFAJhCypuqAGDKCJUC2rVXituiLV1q1rrry0t3i73tve2t732dlHQutRWVFSqVbFicQEUZZGAqGxCQJYEhBASCAnZP78/zgkOIYEZmMmZJJ/n4zGPmTnne858ZmDmne/3bKKqGGOMMaHyeV2AMcaYjsWCwxhjTFgsOIwxxoTFgsMYY0xYLDiMMcaExYLDGGNMWCw4jIkiEfmbiPx3iG03i8hXjnc9xkSbBYcxxpiwWHAYY4wJiwWH6fLcIaIpIvKJiFSJyF9EpJeIvCEilSLytoj0CGp/hYisFpEKEVkgIqcEzTtLRFa4y70AJLZ4rctFZKW77CIROeMYa75NRIpEZI+IzBaR3u50EZE/iMguEdknIp+KyGnuvEtFZI1bW4mI/PCYPjDT5VlwGOO4GrgYGAJ8DXgD+HcgG+d7ci+AiAwBngPuc+fNAV4TkXgRiQdeAZ4GMoC/u+vFXfYs4EngDiATeBSYLSIJ4RQqImOB/wEmAicCW4Dn3dmXAKPd99HdbVPmzvsLcIeqpgKnAfPCeV1jmllwGON4SFV3qmoJsBBYqqofqWoN8DJwltvuWuB1VX1LVeuB3wFJwHlAARAA/qiq9ar6IrAs6DVuBx5V1aWq2qiqTwG17nLhuBF4UlVXqGotcD8wUkT6A/VAKnAyIKq6VlV3uMvVA0NFJE1Vy1V1RZivawxgwWFMs51Bjw+08ryb+7g3zl/4AKhqE7AN6OPOK9FDzxy6JehxLvADd5iqQkQqgL7ucuFoWcN+nF5FH1WdB0wDpgO7ROQxEUlzm14NXApsEZF3RWRkmK9rDGDBYUy4tuMEAOBsU8D58S8BdgB93GnN+gU93gb8SlXTg27JqvrccdaQgjP0VQKgqg+q6jnAUJwhqynu9GWqeiXQE2dIbVaYr2sMYMFhTLhmAZeJyDgRCQA/wBluWgQsBhqAe0UkICL/BowIWvZx4E4ROdfdiJ0iIpeJSGqYNTwH3CIiw9ztI7/GGVrbLCLD3fUHgCqgBmhyt8HcKCLd3SG2fUDTcXwOpguz4DAmDKr6GTAJeAjYjbMh/WuqWqeqdcC/Ad8E9uBsD/lH0LKFwG04Q0nlQJHbNtwa3gZ+BryE08sZBFznzk7DCahynOGsMuABd95NwGYR2QfcibOtxJiwiV3IyRhjTDisx2GMMSYsFhzGGGPCYsFhjDEmLBYcxhhjwuL3uoD2kJWVpf379/e6DGOM6VCWL1++W1WzW07vEsHRv39/CgsLvS7DGGM6FBHZ0tp0G6oyxhgTFgsOY4wxYbHgMMYYE5YusY2jNfX19RQXF1NTU+N1KVGVmJhITk4OgUDA61KMMZ1Elw2O4uJiUlNT6d+/P4eezLTzUFXKysooLi5mwIABXpdjjOkkuuxQVU1NDZmZmZ02NABEhMzMzE7fqzLGtK8uGxxApw6NZl3hPRpj2leXDo6j2VtdR9n+Wq/LMMaYmGLBcQQVB+r5Ym8NDY2Rv95NRUUFDz/8cNjLXXrppVRUVES8HmOMCZUFxxH0TE2gUZWyqrqIr7ut4GhoaDjicnPmzCE9PT3i9RhjTKi67F5VoUiK95OWGGD3/lqyusUT54tczk6dOpWNGzcybNgwAoEAiYmJ9OjRg3Xr1rF+/Xquuuoqtm3bRk1NDd/73ve4/fbbgS9Pn7J//34mTJjA+eefz6JFi+jTpw+vvvoqSUlJEavRGGNaY8EB/OK11azZvq/VeU2qHKhrJN7vIxAXenAM7Z3Gf3zt1Dbn/+Y3v2HVqlWsXLmSBQsWcNlll7Fq1aqDu80++eSTZGRkcODAAYYPH87VV19NZmbmIevYsGEDzz33HI8//jgTJ07kpZdeYtKkSSHXaIwxxyKqQ1UiMl5EPhORIhGZ2kabiSKyRkRWi8hMd1quiKwQkZXu9DuD2i9w17nSvfWM5nvwiRDnE+qjsJ0j2IgRIw451uLBBx/kzDPPpKCggG3btrFhw4bDlhkwYADDhg0D4JxzzmHz5s1RrdEYYyCKPQ4RiQOmAxcDxcAyEZmtqmuC2uQB9wOjVLU8KAR2ACNVtVZEugGr3GW3u/NvVNWIne72SD0DgKraBjaW7ufE7olkpyZG6mUPkZKScvDxggULePvtt1m8eDHJycmMGTOm1WMxEhISDj6Oi4vjwIEDUanNGGOCRbPHMQIoUtVNqloHPA9c2aLNbcB0VS0HUNVd7n2dqjbvB5sQ5TqPKiXBT7cEP6WVdTQ1aUTWmZqaSmVlZavz9u7dS48ePUhOTmbdunUsWbIkIq9pjDGREM0f5D7AtqDnxe60YEOAISLygYgsEZHxzTNEpK+IfOKu47dBvQ2Av7rDVD+TdjrCrVdaIg1NTRHbwyozM5NRo0Zx2mmnMWXKlEPmjR8/noaGBk455RSmTp1KQUFBRF7TGGMiweuN434gDxgD5ADvicjpqlqhqtuAM0SkN/CKiLyoqjtxhqlKRCQVeAm4CZjRcsUicjtwO0C/fv2Ou9CUBD8pCX52768lMyUen+/482rmzJmtTk9ISOCNN95odV7zdoysrCxWrVp1cPoPf/jD467HGGNCEc0eRwnQN+h5jjstWDEwW1XrVfVzYD1OkBzk9jRWARe4z0vc+0pgJs6Q2GFU9TFVzVfV/Ozsw658eEx6pSZQ39jEnurIH9dhjDEdRTSDYxmQJyIDRCQeuA6Y3aLNKzi9DUQkC2foapOI5IhIkju9B3A+8JmI+N12iEgAuBwnVNpFSoKflHg/pZW1NGlktnUYY0xHE7XgUNUG4B5gLrAWmKWqq0XklyJyhdtsLlAmImuA+cAUVS0DTgGWisjHwLvA71T1U5wN5XPdbR8rcXowj0frPbQkIvRMc3od5VE4mtwYYzqCqG7jUNU5wJwW034e9FiB77u34DZvAWe0sr4q4JyoFBuibgl+kt1eR4+UeHx29lljTBdj56oKk4jQMzWBusYmKqrrvS7HGGPanQXHMUhN9JMUiGNXZQ1q2zqMMV2MBccxcLZ1JFLXcOy9jmM9rTrAH//4R6qrq49pWWOMOV4WHMcoLdFPYiCOXZW1x9TrsOAwxnRUXh8A2GE1b+vYuqeavQfqSU+OD2v54NOqX3zxxfTs2ZNZs2ZRW1vL17/+dX7xi19QVVXFxIkTKS4uprGxkZ/97Gfs3LmT7du3c9FFF5GVlcX8+fOj9A6NMaZ1FhwAb0yFLz4Ne7HuKIPrGkFAA3EIQXtYnXA6TPhNm8sGn1b9zTff5MUXX+TDDz9EVbniiit47733KC0tpXfv3rz++uuAcw6r7t278/vf/5758+eTlZUVds3GGHO8bKjqOAhCvN9HUxM0HsfJD998803efPNNzjrrLM4++2zWrVvHhg0bOP3003nrrbf48Y9/zMKFC+nevXsEqzfGmGNjPQ44Ys/gaOJUKdm5HxHI69mNYznnoqpy//33c8cddxw2b8WKFcyZM4ef/vSnjBs3jp///OetrMEYY9qP9TiOU/O2jpr6Riprjny98GDBp1X/6le/ypNPPsn+/fsBKCkpYdeuXWzfvp3k5GQmTZrElClTWLFixWHLGmNMe7MeRwSkJwfYWelj574aUhP9IfU6gk+rPmHCBG644QZGjhwJQLdu3XjmmWcoKipiypQp+Hw+AoEAjzzyCAC3334748ePp3fv3rZx3BjT7qQrHMCWn5+vhYWHXjBw7dq1nHLKKRF7jT1VtRSXH6B/ZgppSYGIrTcSIv1ejTFdg4gsV9X8ltNtqCpC0pPjiY/zHfNxHcYY01FYcESIT4Ts1ASq6xrYXxv6tg5jjOlounRwRLpn0CMlnkCcj137YqfXESt1GGM6jy4bHImJiZSVlUX0h7W511FV10BVbWPE1nusVJWysjISExO9LsUY04l02b2qcnJyKC4uprS0NKLrVVV276tl73YhKzUhous+FomJieTk5HhdhjGmE+mywREIBBgwYEBU1r1o4Sb++/W1/P3OkQzvnxGV1zDGGK902aGqaLrh3H5kpsTz4DsbvC7FGGMizoIjCpLj/dw2eiALN+zmo63lXpdjjDERZcERJZMKcklPDvDQvCKvSzHGmIiy4IiSbgl+bj1/APPW7WJVyV6vyzHGmIix4Iiiyef1Jy3Rb9s6jDGdigVHFKUlBrhl1ADeXLOTtTv2eV2OMcZEhAVHlH1r1AC6JfiZZts6jDGdhAVHlHVPDnDzebnMWbWDDTvtGhrGmI7PgqMdfPv8gSQF4pg233odxpiOL6rBISLjReQzESkSkalttJkoImtEZLWIzHSn5YrIChFZ6U6/M6j9OSLyqbvOB+VYrtXazjJS4rmpIJfXPt7OptL9XpdjjDHHJWrBISJxwHRgAjAUuF5EhrZokwfcD4xS1VOB+9xZO4CRqjoMOBeYKiK93XmPALcBee5tfLTeQyTdesFA4v0+ps/f6HUpxhhzXKLZ4xgBFKnqJlWtA54HrmzR5jZguqqWA6jqLve+TlVr3TYJzXWKyIlAmqouUee0tjOAq6L4HiImOzWBG0bk8srKEraUVXldjjHGHLNoBkcfYFvQ82J3WrAhwBAR+UBElojIwd6DiPQVkU/cdfxWVbe7yxcfZZ3Ny98uIoUiUhjpM+AeqzsuHEicT3jYeh3GmA7M643jfpzhpjHA9cDjIpIOoKrbVPUMYDBws4j0CmfFqvqYquaran52dnaEyz42vdISuX54X15aUUxxebXX5RhjzDGJZnCUAH2Dnue404IVA7NVtV5VPwfW4wTJQW5PYxVwgbt88MUlWltnTLvjwkGIwCMLrNdhjOmYohkcy4A8ERkgIvHAdcDsFm1eweltICJZOENXm0QkR0SS3Ok9gPOBz1R1B7BPRArcvakmA69G8T1EXO/0JK7J78vfC4vZsfeA1+UYY0zYohYcqtoA3APMBdYCs1R1tYj8UkSucJvNBcpEZA0wH5iiqmXAKcBSEfkYeBf4nap+6i5zF/AEUARsBN6I1nuIlu9cOIgmVR59d5PXpRhjTNgkktfcjlX5+flaWFjodRmH+NGLH/PKyu28/6OL6Jlm1wQ3xsQeEVmuqvktp3u9cbzLumvMYBoam3jsPet1GGM6FgsOj/TPSuGqYX14ZukWdu+vPfoCxhgTIyw4PHT32MHUNjTxxMLPvS7FGGNCZsHhoUHZ3bj8jN7MWLyZ8qo6r8sxxpiQWHB47LtjB1Nd18iTH1ivwxjTMVhweGxIr1QmnHYCf/tgM3ur670uxxhjjsqCIwbcM3YwlbUN/HWR9TqMMbHPgiMGnNq7OxcP7cWT739OZY31Oowxsc2CI0bcOzaPfTUNzFi8xetSjDHmiCw4YsTpOd256KRsnli4iaraBq/LMcaYNllwxJDvjsujvLqeZ5ZYr8MYE7ssOGLI2f16cEFeFo8v3MSBukavyzHGmFZZcMSYe8flsXt/HTM/3Op1KcYY0yoLjhgzvH8GBQMzePTdjdTUW6/DGBN7LDhi0L3j8thVWcuswm1Hb2yMMe3MgiMGjRyYSX5uDx5ZsJHaBut1GGNiiwVHDBIR7h2Xx469Nby0vENdUt0Y0wVYcMSoC/KyOLNvOtPnF1Hf2OR1OcYYc5AFR4wSEb43bjAlFQd4eYX1OowxscOCI4ZddFJPTuuTxvQFRTRYr8MYEyMsOGKYiPDdsXlsKatm9sfbvS7HGGMAC46Yd/EpvTj5hFSmzS+isUm9LscYYyw4Yp3P5/Q6NpVW8fqnO7wuxxhjLDg6ggmnnUBez25Mm7eBJut1GGM8ZsHRAfh8wj1jB7N+537mrv7C63KMMV1cVINDRMaLyGciUiQiU9toM1FE1ojIahGZ6U4bJiKL3WmfiMi1Qe3/JiKfi8hK9zYsmu8hVlx+Rm8GZqXw4LwiVK3XYYzxTtSCQ0TigOnABGAocL2IDG3RJg+4HxilqqcC97mzqoHJ7rTxwB9FJD1o0SmqOsy9rYzWe4glcT7h7osGs3bHPt5eu8vrcowxXVg0exwjgCJV3aSqdcDzwJUt2twGTFfVcgBV3eXer1fVDe7j7cAuIDuKtXYIVw7rTb+MZB58Z4P1OowxnolmcPQBgk/vWuxOCzYEGCIiH4jIEhEZ33IlIjICiAc2Bk3+lTuE9QcRSWjtxUXkdhEpFJHC0tLS43snMcIf5+PuiwbxacleFqzvHO/JGNPxeL1x3A/kAWOA64HHg4ekRORE4GngFlVtPnT6fuBkYDiQAfy4tRWr6mOqmq+q+dnZnaez8vWzcuiTnsSf3rZehzHGG9EMjhKgb9DzHHdasGJgtqrWq+rnwHqcIEFE0oDXgZ+o6pLmBVR1hzpqgb/iDIl1GfF+H98ZM4iV2yp4v2i31+UYY7qgaAbHMiBPRAaISDxwHTC7RZtXcHobiEgWztDVJrf9y8AMVX0xeAG3F4KICHAVsCqK7yEmXZOfwwlpibatwxjjiagFh6o2APcAc4G1wCxVXS0ivxSRK9xmc4EyEVkDzMfZW6oMmAiMBr7Zym63z4rIp8CnQBbw39F6D7EqwR/HnRcOZNnmcpZs2uN1OcaYLka6wl+s+fn5WlhY6HUZEVVT38gF/zufvJ7dmHlbgdflGGM6IRFZrqr5Lad7vXHcHKPEQBx3jB7Ioo1lLNtsvQ5jTPux4OjAbji3H5kp8Tz4zgavSzHGdCEWHB1Ycryf20YPZOGG3Xy0tdzrcowxXYQFRwc3qSCX9OQAD80r8roUY0wXYcHRwXVL8HPr+QOYt24Xq0r2el2OMaYLsODoBCaf15+0RL9t6zDGtAsLjk4gLTHALaMG8Oaanazdsc/rcowxnZwFRyfxrVED6JbgZ5pt6zDGRJkFRyfRPTnAzeflMmfVDjbsrPS6HGNMJ2bB0Yl8+/yBJAXimDbfeh3GmOix4OhEMlLiuakgl9c+3s6m0v1el2OM6aRCCg4R+Z6IpInjLyKyQkQuiXZxJny3XjCQeL+P6fM3Hr2xMcYcg1B7HN9S1X3AJUAP4CbgN1Gryhyz7NQEbhiRyysrS9haVu11OcaYTijU4BD3/lLgaVVdHTTNxJg7LhxInE94eIFt6zDGRF6owbFcRN7ECY65IpIKNB1lGeORXmmJXD+8Ly8uL6a43HodxpjICjU4vg1MBYarajUQAG6JWlXmuN1x4SBE4JEFtq3DGBNZoQbHSOAzVa0QkUnATwE7MVIM652exDX5ffl7YTE79h7wuhxjTCcSanA8AlSLyJnAD4CNwIyoVWUi4jsXDqJJlUff3eR1KcaYTiTU4GhQ5xqzVwLTVHU6kBq9skwk9M1I5t/O7sNzH25l174ar8sxxnQSoQZHpYjcj7Mb7usi4sPZzmFi3N0XDaahSXnsPet1GGMiI9TguBaoxTme4wsgB3ggalWZiMnNTOHKM3vzzNIt7N5f63U5xphOIKTgcMPiWaC7iFwO1KiqbePoIO4eO5jahiaeWPh5dF9I1bkZYzo1fyiNRGQiTg9jAc6Bfw+JyBRVfTGKtXUuqqBN0FgPTQ3QVA9Njcfx3L0d6bn7eFBTPU+esIPtSyqprTmBBF9j+Os6+LzRraWV500NkJ4LX/01nHwZiB0jakxnFFJwAD/BOYZjF4CIZANvA507OBb+H2z/CBobQvwxb+XHPXieF3x+8AUYLXHsAxrWxJOQmOhMj3Pmffk46HkgCRJS3edxEBcImt/Gc4mDdf+EF26EvEtgwm8hY6A379sYEzWhBoevOTRcZXSFM+tWbIOyjc4P48Ef2AD448GX8uXzQ+a3+AE+0vPDlj2OdbX23Bd38K/+OOAnzy5n4frdvP/9sXRPitK+DRf+CJY+Cgv+B6YXwAXfh1H3QSAxOq9njGl3oiGMSYvIA8AZwHPupGuBT1T1x1GsLWLy8/O1sLDQ6zI8t2b7Pi59cCH/7ytD+N5X8qL7Yvu2w9yfwOp/QI/+MOEBGGInVDamIxGR5aqa33J6qBvHpwCP4YTHGcBjoYSGiIwXkc9EpEhEprbRZqKIrBGR1SIy0502TEQWu9M+EZFrg9oPEJGl7jpfEJH4UN6DgaG907h4aC/+8v4mKmuiPHSW1huu+StMfhXi4mHmNfD8jVCxNbqva4yJupCHm1T1JVX9vnt7+WjtRSQOmA5MAIYC14vI0BZt8oD7gVGqeipwnzurGpjsThsP/FFE0t15vwX+oKqDgXKc82iZEN07No99NQ3MWLylfV5w4Bi48wMY9x+wcR5MGwHv/Q4abNdgYzqqIwaHiFSKyL5WbpUisu8o6x4BFKnqJlWtA57HOfI82G3AdFUtB2jejqKq61V1g/t4O7ALyBYRAcby5Ub5p4CrQn+75vSc7lx0UjZPLNxEVW1D+7yoP97Z1nH3h5D3FZj3X/DIebBxfvu8vjEmoo4YHKqaqqpprdxSVTXtKOvuA2wLel7sTgs2BBgiIh+IyBIRGd9yJSIyAojHOT9WJlChqs2/eK2ts3m520WkUEQKS0tLj1Jq1/LdcXmUV9fzzJJ26nU0S+8L1z4DN77k7H329FUw62bYW9K+dRhjjovXe0b5gTxgDHA98HjQkBQiciLwNHCLqoZ1/Q9VfUxV81U1Pzs7O4Ild3xn9+vBBXlZPL5wEwfqGtu/gLyvwF1L4KKfwPp/wbTh8MGfnF2XjTExL5rBUQL0DXqe404LVgzMVtV6Vf0cWI8TJIhIGvA68BNVXeK2LwPSRcR/hHWaENw7Lo/d++uY+aFHG6sDic6uu3ctgQEXwFs/hz+fD58v9KYeY0zIohkcy4A8dy+oeOA6YHaLNq/g9DYQkSycoatNbvuXgRnBR6e7Z+idD3zDnXQz8GoU30OnNbx/BgUDM3j03Y3U1HvQ62iWMQBueAGufx7qq+Gpy+Gl26Byp3c1GWOOKGrB4W6HuAeYC6wFZqnqahH5pYhc4TabC5SJyBqcQJiiqmXARGA08E0RWenehrnL/Bj4vogU4Wzz+Eu03kNnd++4PHZV1jKrcNvRG0fbSRPgrqUwegqseQWm5cOSR5yj9o0xMSWkAwA7OjsAsHWqyjV/XkxJxQEWTBlDgj/O65IcZRthzhTY+A70Og0u+z/oV+B1VcZ0Ocd1AKDpnESEe8flsWNvDS8tj6FNRZmDYNJLMHEGHCiHJ78Kr9wF+23vOGNigQVHF3dBXhbD+qbz8IIi6hvD2nEtukRg6JXOsR+j7oNPXoBp58CyJ5xdeY0xnrHg6OKcXsdgissP8PJHMdTraJbQDS7+BXxnEZxwBrz+A3h8LBQv97oyY7osCw7DRSf15LQ+aUyfX0RDLPU6gmWfBDe/Blf/BSq/gCfGwWvfg+o9XldmTJdjwWEQEb47No8tZdXM/ni71+W0TQRO/wbcswwK7oIVT8ND58Dyp6ApRgPPmE7IgsMAcPEpvTj5hFSmzS+isSnG97RLTIPxv4Y7F0L2yfDavfDkJbDjY68rM6ZLsOAwAPh8Tq9jU2kVr3+6w+tyQtPrVLhlDlz1ZyjfDI+NcXbjPVDhdWXGdGoWHOagCaedQF7Pbkybt4GmWO91NBOBYdfDPYUw/FZnr6tp+bDyOec678aYiLPgMAf5fMI9Ywezfud+5q7+wutywpOUDpc+ALfNh/RceOVO+OsE2Lna68qM6XQsOMwhLj+jNwOzUnhwXhEd8qwCvYfBt9+CKx6C0s/gzxfAv/4dao52+RhjTKgsOMwh4nzC3RcNZu2Ofby9dpfX5Rwbnw/OngzfXQ5n3wRLHnZO3f7pizZ8ZUwEWHCYw1w5rDf9MpJ58J0NHbPX0Sw5A772J7j1HUg9AV76Njz1NacnYow5ZhYc5jD+OB93XzSIT0v2smB9Jzg/VM45cNs852SJX3ziXLb2rZ9D7X6vKzOmQ7LgMK36+lk59ElP6vi9jma+OGevq++ugDOuc644OH0ErHnVhq+MCZMFh2lVvN/Hd8YM4qOtFXxQVOZ1OZGTkgVXTYdvzYWkHjBrMjxztXMqd2NMSCw4TJuuyc/hhLRE/vTO+s7R6wjWrwBufxfG/xaKl8HDBTDvv6Gu2uvKjIl5FhymTQn+OO68cCDLNpezZFMnPJlgnB8K7nTOfTX0KnjvAXj4XFg3x+vKjIlpFhzmiK4b0Y/s1AQemrfB61KiJ/UEuPpxuPmfEEiG56+Hmdc6pzExxhzGgsMcUWIgjjtGD2TRxjIKN3fCXkewARfAne/Dxf8Fny+E6efCgt9CfY3XlRkTUyw4zFHdeG4umSnxPDivyOtSoi8uAKPudYavTpoAC37tbP/Y8LbXlRkTMyw4zFElxcdx2+iBvLe+lI+2lntdTvvo3geu+Rvc9LKzK++zV8MLk6Bim9eVGeM5Cw4TkkkFuaQnB3ioK/Q6gg0a61y2duzPnF7H9BGw8PfQUOd1ZcZ4xoLDhKRbgp9bzx/AvHW7WFWy1+ty2pc/AUb/EO750AmSd37hHH2+aYHXlRnjCQsOE7LJ5/UnLdHPg+904j2sjiS9H1z3LNzwd2hqgBlXwt9vgX0xfLldY6LAgsOELC0xwC2jBvDmmp2s3dGFT1M+5BK4awmMuR/Wve6ceXfRQ9BY73VlxrSLqAaHiIwXkc9EpEhEprbRZqKIrBGR1SIyM2j6v0SkQkT+2aL930TkcxFZ6d6GRfM9mEN9a9QAuiX4mdbVtnW0FEiEMVPh7iWQex68+VN4dDRs/sDryoyJuqgFh4jEAdOBCcBQ4HoRGdqiTR5wPzBKVU8F7gua/QBwUxurn6Kqw9zbyshXb9rSPTnAzeflMmfVDjbsrPS6HO9lDIQbZsF1M52z7f7tUvjH7VC50+vKjImaaPY4RgBFqrpJVeuA54ErW7S5DZiuquUAqnrwykGq+g5gv0wx6NvnDyQpEMe0+V2819FMBE6+DO5eChf8AFb9w7nu+dJHobHB6+qMibhoBkcfIHin92J3WrAhwBAR+UBElojI+BDX/SsR+URE/myLOukAABQISURBVCAiCa01EJHbRaRQRApLSzvBNSViSEZKPDcV5PLax9vZVGrXtDgoPhnG/dzZ/tHnHHjjR/D4GNj2odeVGRNRXm8c9wN5wBjgeuBxEUk/yjL3AycDw4EM4MetNVLVx1Q1X1Xzs7OzI1exAeDWCwYS7/cxfb6djvwwWYOdAwev+RtUlcFfLoZX74aq3V5X1vGoOmcsriqDiq2w53OorbRrqHjMH8V1lwB9g57nuNOCFQNLVbUe+FxE1uMEybK2VqqqO9yHtSLyV+CHkSvZhCo7NYEbz83lb4s2871xefTLTPa6pNgiAqd+HQZfDO/+1rnu+dp/Oj2Sc77pHI3eGTQ1Qn218+Ne33w7AHVVzn29e3/I/Ob2bcxv2bY1/iTolg0pPaFbT0jJdu97Hj49sbvz72EiJprBsQzIE5EBOIFxHXBDizav4PQ0/ioiWThDV5uOtFIROVFVd4iIAFcBqyJeuQnJHaMH8vSSLTy8oIjfXH2G1+XEpoRucMl/wbAbYM4UeP378NHTzmVs+5wT3ddWhca6Nn6om3/YW/uxDmN+Y234dQWSIZAEgRTnPj7ZmZacCYEciHenB9zpzfMDyU4AVO2GqlLYvwuqdkH5FueaKtVloE2Hv15cfItAaStwekJiOvi8HoiJfVELDlVtEJF7gLlAHPCkqq4WkV8Chao62513iYisARpx9pYqAxCRhThDUt1EpBj4tqrOBZ4VkWxAgJXAndF6D+bIeqYlcv3wvjy7dCv3jB1MTg/rdbSp5ylw82vw6Yvw5k/g8XFOz2PMVPD5j+8v9CPN18bw6pS4Nn64k5wrJgb/0LecfzAIjvDD70+M3g9zU6MTHs2Bsr/Uvd/1ZdBUbocdHzvPW/tsfH4nTI7Ug2menpzReXqOYZJOd2W3VuTn52thYaHXZXRK2ysOcOED85mY35dfff10r8vpGGr2woLfOHtdhfvDHpdw9B/ng/OTW7RNOfoPf1ygawzrNDXBgfLDg6WtwGlq5eBO8UFyVotAaSNwkrOcC4d1MCKyXFXzW07veO/ExJTe6Ulck9+XvxcWc8/YwZzYPcnrkmJfYncY/z9w1iQoesf5KzyUv9r9SR3yxycm+XyQkuncep5y5LaqUFPReqAEB03ZRue+obXrt4jTQzniUJk7PSUb/PFReduRYv8LzXH7zoWDmLVsG4++u4n/vOJUr8vpOHqd6txMbBNxhumSekD2kCO3VXX2+jokWIKDxr0vKXQCp76q9fUkpn8ZLEcbNgu0/x9rFhzmuPXNSObfzu7Dcx9u5a4xg+iZluh1ScZ4QwQS05xb5qCjt6+rOvpQ2RefOve1bZwfLj71yBv+B1zo1BNBFhwmIu6+aDAvrSjhT+9s4JdXnkacrwuMkxtzvOJTIGOAczua+ppWgiX4eSmUfuZc9rim4svl7im04DCxKTczhYn5OTy7dCsLPitlUkEu1w7vS0ZKbI/VGtNhBBKdU/un9zt624Y6p5dStSu09mGyvapMxDQ0NvH22p08tWgLizeVEe/3ccWZvbl5ZH9Oz+nudXnGmDC1tVeVBYeJivU7K5mxeDP/WFFCdV0jZ/VLZ/LIXC49/UQS/F1z33djOhoLDgsOT+yrqeel5cU8vXgLm3ZXkZkSz/Uj+nFjQT/bddeYGGfBYcHhqaYm5f2i3cxYvIV31u3EJ8IlQ3sxeWR/CgZmIF3hoDNjOhg7ANB4yucTRg/JZvSQbLbtqeaZpVt4Ydk23lj1BUN6dWPyyP58/aw+pCTYf0ljYp31OIxnauobmf3xdp5atJnV2/eRmuDnG/k53FSQy8Dsbl6XZ0yXZ0NVFhwxS1VZsbWCGYs3M+fTHdQ3KqOHZHPzyFzGnNTTjgkxxiMWHBYcHcKuyhqe/3Abzy7dws59tfTNSOKmglwm5vclPdmOCTGmPVlwWHB0KPWNTby5eidPLd7Mh5/vIcHv46phfbhpZC6n9bFjQoxpDxYcFhwd1tod+5ixeAuvfFTCgfpG8nN7MPm8/ow/9QTi/XbRHWOixYLDgqPD21tdz9+Xb+PpJVvYUlZNdmoCN4zoxw3n9qOXnVjRmIiz4LDg6DSampT3NpQyY/EW5n+2izgRxp92Ajef15/83B52TIgxEWLHcZhOw+cTxpzUkzEn9WRLWRXPLHGOCfnnJzs45cQ0bh6Zy5XD+pAUb6c2MSYarMdhOoUDdY28urKEvy3azLovKklL9DMxvy83jcwlNzPF6/KM6ZBsqMqCo0tQVQq3lPPUos38a9UXNKoyZkg2k8/rz4V52fjsmBBjQmZDVaZLEBGG989geP8Mdu6rYebSrcz8cCu3/HUZ/TOTmVSQyzX5femeFPC6VGM6LOtxmE6vrqGJf63+ghmLNlO4pZykQBxXndWHySNzOeXEyF4ZzZjOxIaqLDgMsKpkL08v3sIrK0uobWhixIAMbh7Zn0tO7UUgzo4JMSaYBYcFhwlSUV3HrELnmJBtew7QKy2BG8/N5boRfemZaseEGAMWHBYcplWNTcqCz3bx1OItvLe+lECccOnpJzJ5ZH/O7pdux4SYLq2t4Ihq31xExovIZyJSJCJT22gzUUTWiMhqEZkZNP1fIlIhIv9s0X6AiCx11/mCiNiZ78wxi/MJ407pxYxvjWDeDy5kUkEu89bu4upHFvG1ae8zq3AbNfWNXpdpTEyJWo9DROKA9cDFQDGwDLheVdcEtckDZgFjVbVcRHqq6i533jggGbhDVS8PWmYW8A9VfV5E/gx8rKqPHKkW63GYcFTVNvDyRyXMWLyZ9Tv3k54c4NrhfZl0bi59M5K9Ls+YduNFj2MEUKSqm1S1DngeuLJFm9uA6apaDtAcGu7jd4DK4MbijBuMBV50Jz0FXBWd8k1XlZLgZ1JBLnPvG81ztxUwcmAmTyz8nNEPzOfWpwpZuKGUpqbOP8RrTFuieRxHH2Bb0PNi4NwWbYYAiMgHQBzwn6r6ryOsMxOoUNWGoHX2iUy5xhxKRBg5KJORgzLZXnGAmUu38vyyrbz9l50MzE5hckEuV5+TQ2qiHRNiuhav9z/0A3nAGOB64HERSY/EikXkdhEpFJHC0tLSSKzSdGG905P44VdP4oOpY/njtcPonhTgP19bQ8Gv3+Fnr6xiw87Ko6/EmE4imj2OEqBv0PMcd1qwYmCpqtYDn4vIepwgWdbGOsuAdBHxu72O1tYJgKo+BjwGzjaOY34XxgRJ8DsHD151Vh8+Ka5gxuItvODu1jtyYCY3n5fLV07phd+OCTGdWDT/dy8D8ty9oOKB64DZLdq8gtPbQESycIauNrW1QnW25M8HvuFOuhl4NbJlGxOaM3LS+d01Z7Lk/nH8ePzJbN1TzZ3PrOCC/53P9PlF7N5f63WJxkRFVI/jEJFLgT/ibL94UlV/JSK/BApVdba7sfv/gPFAI/ArVX3eXXYhcDLQDaen8W1VnSsiA3E2tGcAHwGTVPWI31Dbq8q0h8Ym5Z21O5mxeAvvF+0mPs7H5WecyOTz+jOsb0RGYI1pV3YAoAWHaUdFuyp5evEWXlxeTFVdI2fmdGfyyP5cdsaJJAbsOiGmY7DgsOAwHqisqeflj0p4atFmNpZWkZESz3XD+3JjQS590pO8Ls+YI7LgsOAwHlJVFm0s46lFm3l77U4ALh7ai6+f1YdeaYlkpMTTIyWe1AS/nebExAy7HocxHhIRRg3OYtTgLIrLq3l26Vae/3Arc1fvPKSd3yf0SIknIzmeHikBJ1CS4w+9bzE/KRBnYWPalfU4jPFITX0j676opLyqjj1VdZRXt7ivqmdPdR3l7rS2DlZP8PsOC5YeyYE2g6ZHcrxtZzEhsR6HMTEmMRAX8t5WTU3Kvpr6oGCpdwLHDRZnej3l1XVsL9nLnuo6Kqrr21xfcnxci2AJBAVMyx6OE0J2vRLTzILDmA7A5xPSk+NJTw79ZNANjU3sPVB/MGgO7c0EhU51PZt3V1FeVUdlbUOb60tN9JOR4tRwpKDJcIMmPTmeOLvGe6dkwWFMJ+WP85HZLYHMbgkhL1PX0ERFtRMqLYfL9lTVufPq2b2/jvU791NeXUd1XeunnReB7kmBg+HiBEuLwAkKnozkeFIT/fgsbGKeBYcx5qB4v4+eaYn0TAv9Kog19Y2tbpdpud2mpOIAq0r2sqeqjrrGplbXFecT0pMCbe4gkO6GS1pi4OB9WpKfbgl+O81LO7LgMMYcl8RAHCd2T+LE7qEdl6KqVNc1trJDQP3BHQGap2/eXc2KrRWUV9XRcJRT2SfHxx0SKqmJAdKSmh+7IeNOT030B81z7rvFW28nVBYcxph2JSKkJPhJSfCHfGEsVaWytsHZDlPTwL6aeuf+gHP/5bQvn5dX17F1TzWVNfXsO9DQZi/ny7qgW8KhvZmDodMiZILDqXvSl9O7yq7RFhzGmJgnIm6P4divfVJT3+iGSj373PtDw8eZvq/my+c79tawfteX7Y52/S6/T9oMmOYASnPDKNV9Py3DKcEf+7tKW3AYY7qExEAciYE4slND31kgWPMQ25ch0xxAh4ZPZYvw2VJW/WVP6Ah7rTWL9/tIO2zIzU9qQovnLcIpOISivb3HgsMYY0IQPMR2QvfQdx4I1tik7K9tpbdTe+jzw3s+Bw4OwR2ob30vtmDN23tSEwM8MTmf/lkpx1RvWyw4jDGmncT5hO5JAbonHfuQW31j06G9mwMtht6CAmffgQaSEyI/9GXBYYwxHUggzuceaBn6waCRZjs+G2OMCYsFhzHGmLBYcBhjjAmLBYcxxpiwWHAYY4wJiwWHMcaYsFhwGGOMCYsFhzHGmLB0iWuOi0gpsOUYF88CdkewnEixusJjdYXH6gpPZ60rV1WzW07sEsFxPESksLWLtXvN6gqP1RUeqys8Xa0uG6oyxhgTFgsOY4wxYbHgOLrHvC6gDVZXeKyu8Fhd4elSddk2DmOMMWGxHocxxpiwWHAYY4wJiwWHS0TGi8hnIlIkIlNbmZ8gIi+485eKSP8YqeubIlIqIivd263tUNOTIrJLRFa1MV9E5EG35k9E5Oxo1xRiXWNEZG/QZ/Xzdqqrr4jMF5E1IrJaRL7XSpt2/8xCrKvdPzMRSRSRD0XkY7euX7TSpt2/jyHW1e7fx6DXjhORj0Tkn63Mi+znpapd/gbEARuBgUA88DEwtEWbu4A/u4+vA16Ikbq+CUxr589rNHA2sKqN+ZcCbwACFABLY6SuMcA/Pfj/dSJwtvs4FVjfyr9ju39mIdbV7p+Z+xl0cx8HgKVAQYs2XnwfQ6mr3b+PQa/9fWBma/9ekf68rMfhGAEUqeomVa0DngeubNHmSuAp9/GLwDgRkRioq92p6nvAniM0uRKYoY4lQLqInBgDdXlCVXeo6gr3cSWwFujTolm7f2Yh1tXu3M9gv/s04N5a7sXT7t/HEOvyhIjkAJcBT7TRJKKflwWHow+wLeh5MYd/gQ62UdUGYC+QGQN1AVztDm+8KCJ9o1xTKEKt2wsj3aGGN0Tk1PZ+cXeI4Cycv1aDefqZHaEu8OAzc4ddVgK7gLdUtc3Pqx2/j6HUBd58H/8I/AhoamN+RD8vC46O7zWgv6qeAbzFl39VmMOtwDn3zpnAQ8Ar7fniItINeAm4T1X3tedrH8lR6vLkM1PVRlUdBuQAI0TktPZ43aMJoa52/z6KyOXALlVdHu3XambB4SgBgv8yyHGntdpGRPxAd6DM67pUtUxVa92nTwDnRLmmUITyebY7Vd3XPNSgqnOAgIhktcdri0gA58f5WVX9RytNPPnMjlaXl5+Z+5oVwHxgfItZXnwfj1qXR9/HUcAVIrIZZzh7rIg806JNRD8vCw7HMiBPRAaISDzOxqPZLdrMBm52H38DmKfuliYv62oxDn4Fzji112YDk909hQqAvaq6w+uiROSE5nFdERmB8/8/6j827mv+BVirqr9vo1m7f2ah1OXFZyYi2SKS7j5OAi4G1rVo1u7fx1Dq8uL7qKr3q2qOqvbH+Y2Yp6qTWjSL6OflP9YFOxNVbRCRe4C5OHsyPamqq0Xkl0Chqs7G+YI9LSJFOBtgr4uRuu4VkSuABreub0a7LhF5DmdvmywRKQb+A2dDIar6Z2AOzl5CRUA1cEu0awqxrm8A3xGRBuAAcF07hD84fxHeBHzqjo8D/DvQL6g2Lz6zUOry4jM7EXhKROJwgmqWqv7T6+9jiHW1+/exLdH8vOyUI8YYY8JiQ1XGGGPCYsFhjDEmLBYcxhhjwmLBYYwxJiwWHMYYY8JiwWFMjBPnDLWHnfHUGK9YcBhjjAmLBYcxESIik9zrNawUkUfdE+LtF5E/uNdveEdEst22w0RkiXsyvJdFpIc7fbCIvO2eVHCFiAxyV9/NPWneOhF5th3OzGxMmyw4jIkAETkFuBYY5Z4ErxG4EUjBOXr3VOBdnKPZAWYAP3ZPhvdp0PRngenuSQXPA5pPO3IWcB8wFOf6LKOi/qaMaYOdcsSYyBiHc0K7ZW5nIAnn1NtNwAtum2eAf4hIdyBdVd91pz8F/F1EUoE+qvoygKrWALjr+1BVi93nK4H+wPvRf1vGHM6Cw5jIEOApVb3/kIkiP2vR7ljP8VMb9LgR++4aD9lQlTGR8Q7wDRHpCSAiGSKSi/Md+4bb5gbgfVXdC5SLyAXu9JuAd92r8BWLyFXuOhJEJLld34UxIbC/WoyJAFVdIyI/Bd4UER9QD9wNVOFc8OenOENX17qL3Az82Q2GTXx5NtybgEfdM5vWA9e049swJiR2dlxjokhE9qtqN6/rMCaSbKjKGGNMWKzHYYwxJizW4zDGGBMWCw5jjDFhseAwxhgTFgsOY4wxYbHgMMYYE5b/D/dZpGLSjm8EAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we create a function called <code>showRecommendationsUser</code> to show the top 10 movie recommendations for a given user. The input parameters are a recommender model and the specified <code>user_id</code> from the <code>df</code> Dataframe.</p>"
      ],
      "metadata": {
        "id": "j9AlMuIrmCQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showRecommendationsUser(model, user_id= df.userId.sample(1).iloc[0]):\n",
        "  movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "# Let us get a user and see the top recommendations.\n",
        "  movies_watched_by_user = df[df.userId == user_id]\n",
        "  movies_not_watched = movie_df[\n",
        "      ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "  ][\"movieId\"]\n",
        "  movies_not_watched = list(\n",
        "      set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        "  )\n",
        "  movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "  user_encoder = user2user_encoded.get(user_id)\n",
        "  user_movie_array = np.hstack(\n",
        "      ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        "  )\n",
        "  ratings = model.predict(user_movie_array).flatten()\n",
        "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "  recommended_movie_ids = [\n",
        "      movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "  ]\n",
        "  print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Movies with high ratings from user\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_user = (\n",
        "      movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "      .head(5)\n",
        "      .movieId.values\n",
        "  )\n",
        "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "  for row in movie_df_rows.itertuples():\n",
        "      print(row.title, \":\", row.genres)\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 movie recommendations\")\n",
        "  print(\"----\" * 8)\n",
        "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "  for row in recommended_movies.itertuples():\n",
        "      print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "gTtNeWMhmA4s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Using our function, we show the top 10 movie recommendations for <code>user_id</code> 420 generated by our first recommender model.</p>"
      ],
      "metadata": {
        "id": "fXfo39KLKhJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= first_model, user_id= 420)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rsh2Y_kZYBc",
        "outputId": "816cdd2b-8104-4375-ac70-05bf48cc3fdd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
            "Ghost in the Shell (Kôkaku kidôtai) (1995) : Animation|Sci-Fi\n",
            "Godfather, The (1972) : Crime|Drama\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "L.A. Confidential (1997) : Crime|Film-Noir|Mystery|Thriller\n",
            "Good Will Hunting (1997) : Drama|Romance\n",
            "Saving Private Ryan (1998) : Action|Drama|War\n",
            "Boondock Saints, The (2000) : Action|Crime|Drama|Thriller\n",
            "Departed, The (2006) : Crime|Drama|Thriller\n",
            "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 2</h1>\n",
        "\n",
        "<p>Now, inside of a function <code>showRecommendationsTJ()</code>, we create a feature vector for one member of our team, Timothy Jan. We pick some movies, assign a rating to each of them, and create a new Dataframe. It is then used to generate 10 movie recommendations using the recommender model passed by the input <code>model</code>.</p>"
      ],
      "metadata": {
        "id": "U4sdnup1jBwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showRecommendationsTJ(model):\n",
        "  tj_movie_ID = [121231, 122900, 122902, 122904, 122906, 122912, 122916, 122918, 122920, 122922, 125916, 128360, 131739, 134130, 134853, 140715, 140956, 159858, 161354, 161594, 162082, 163645, 164367, 166024, 166528, 167370, 168248, 168252, 168366, 174053, 174055, 176101, 177285, 177593, 177763, 177765, 179401, 179819, 180031, 180985, 182715, 183635, 184471, 185029, 185135, 185585, 187031, 187593, 189713, 188189, ]\n",
        "  tj_movie_ratings = [2.5, 3.5, 2.5, 3.75, 4.25, 4.25, 4.25, 3.5, 3.75, 3.25, 1.5, 4, 3.75, 4, 3.5, 3.75, 4, 3.75, 3.75, 4.25, 4.5, 4.25, 4.5, 4, 3.75, 0.5, 4.25, 3.5, 2, 4, 2.5, 3, 3.25, 4, 4, 3.5, 3, 3, 4.25, 3, 4, 2, 2.5, 4.5, 4.25, 4, 2.5, 3.5, 3.5, 4.5, ]\n",
        "  tj_dict = {'movieId': tj_movie_ID, 'rating':tj_movie_ratings}\n",
        "  movies_watched_by_tj = pd.DataFrame(tj_dict)\n",
        "  movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "  movies_not_watched_by_tj = movie_df[\n",
        "      ~movie_df[\"movieId\"].isin(movies_watched_by_tj.movieId.values)\n",
        "  ][\"movieId\"]\n",
        "  movies_not_watched_by_tj = list(\n",
        "      set(movies_not_watched_by_tj).intersection(set(movie2movie_encoded.keys()))\n",
        "  )\n",
        "  movies_not_watched_by_tj = [[movie2movie_encoded.get(x)] for x in movies_not_watched_by_tj]\n",
        "  user_encoder = 609 #must be in range, does not affect prediction. tested\n",
        "  user_movie_array = np.hstack(\n",
        "      ([[user_encoder]] * len(movies_not_watched_by_tj), movies_not_watched_by_tj)\n",
        "  )\n",
        "  ratings = model.predict(user_movie_array).flatten()\n",
        "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "  recommended_movie_ids = [\n",
        "      movie_encoded2movie.get(movies_not_watched_by_tj[x][0]) for x in top_ratings_indices\n",
        "  ]\n",
        "  print(\"Showing recommendations for user: TJ\")\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Movies with high ratings from user\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_user = (\n",
        "      movies_watched_by_tj.sort_values(by=\"rating\", ascending=False)\n",
        "      .head(5)\n",
        "      .movieId.values\n",
        "  )\n",
        "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "  for row in movie_df_rows.itertuples():\n",
        "      print(row.title, \":\", row.genres)\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 movie recommendations\")\n",
        "  print(\"----\" * 8)\n",
        "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "  for row in recommended_movies.itertuples():\n",
        "      print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "diNgP--h9RlS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Using our function, we show the top 10 movie recommendations for our team member generated by our first recommender model.</p>"
      ],
      "metadata": {
        "id": "_NRpuc6vlUYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(first_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z2ySvqJZ0zu",
        "outputId": "a309e69b-93af-41f1-e2e5-51eb57903c04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "North by Northwest (1959) : Action|Adventure|Mystery|Romance|Thriller\n",
            "Casablanca (1942) : Drama|Romance\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) : Action|Adventure|Sci-Fi\n",
            "Princess Bride, The (1987) : Action|Adventure|Comedy|Fantasy|Romance\n",
            "Apocalypse Now (1979) : Action|Drama|War\n",
            "Goodfellas (1990) : Crime|Drama\n",
            "Godfather: Part II, The (1974) : Crime|Drama\n",
            "Chinatown (1974) : Crime|Film-Noir|Mystery|Thriller\n",
            "Shining, The (1980) : Horror\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>The results showed good recommendations and were similar to the highest-rated movies for the user.</p>"
      ],
      "metadata": {
        "id": "aAodtZHep6Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 3</h1>\n",
        "\n",
        "<p>To improve our results, we replaced the dot product with three <code>Dense</code> layers in our recommender model. We compiled it using the <code>BinaryCrossentropy</code> loss function and the <code>Adam</code> optimizer with a learning rate of 0.001.</p>"
      ],
      "metadata": {
        "id": "crg2CyxVi9hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class improvedRecommender(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(improvedRecommender, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "        self.user_movie_relationship1 = tf.keras.layers.Dense(100, activation= \"relu\")# use_bias= False)#, input_shape = (64,)\n",
        "        self.user_movie_relationship2 = tf.keras.layers.Dense(50, activation= \"relu\")# use_bias= False)#, input_shape = (64,)\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation= \"sigmoid\", input_shape= (50,))#, use_biase=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        \n",
        "        concat_inputs = tf.concat([user_vector, movie_vector], 1)\n",
        "        concat_bias = user_bias + movie_bias\n",
        "        response = self.user_movie_relationship1(concat_inputs)\n",
        "        response = self.user_movie_relationship2(response)\n",
        "        response = response + concat_bias\n",
        "        response = self.output_layer(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "new_model = improvedRecommender(num_users, num_movies, EMBEDDING_SIZE)\n",
        "new_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "gFcxvVMiZKEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b563e1-51db-4f4a-bbea-a745c5cbc4f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We fit the new model to our dataset. We used a batch size of 64, 5 epochs, and a verbosity of 1. After training, we achieve a <code>loss</code> of 0.5600 and a <code>val_loss</code> of 0.6109, which is an improvement over our first model.</p>"
      ],
      "metadata": {
        "id": "N2R36mOcqUH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "id": "BlG9IdSVvcVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbf9a8c-0422-446a-a361-90eb303adab4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 6s 4ms/step - loss: 0.6048 - val_loss: 0.6013\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5902 - val_loss: 0.6006\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5821 - val_loss: 0.6021\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5723 - val_loss: 0.6041\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5623 - val_loss: 0.6108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 4</h1>\n",
        "\n",
        "<p>Now we call our functions using our new recommender model and the same users.</p>"
      ],
      "metadata": {
        "id": "4O8JC2ss3jYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= new_model, user_id= 420)"
      ],
      "metadata": {
        "id": "x6AdaniTvdmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8660db-1d67-46ff-cc98-eef416a6f36c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Tales from the Crypt Presents: Demon Knight (1995) : Horror|Thriller\n",
            "Seventh Seal, The (Sjunde inseglet, Det) (1957) : Drama\n",
            "Howl's Moving Castle (Hauru no ugoku shiro) (2004) : Adventure|Animation|Fantasy|Romance\n",
            "Kingdom, The (2007) : Action|Drama|Thriller\n",
            "Hunger (2008) : Drama\n",
            "Eichmann (2007) : Drama|War\n",
            "Louis C.K.: Oh My God (2013) : Comedy\n",
            "Prisoners (2013) : Drama|Mystery|Thriller\n",
            "Band of Brothers (2001) : Action|Drama|War\n",
            "Three Billboards Outside Ebbing, Missouri (2017) : Crime|Drama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgSxUQUN3XgK",
        "outputId": "2e99cb8d-1777-46ba-86ed-8815acebd733"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Pulp Fiction (1994) : Comedy|Crime|Drama|Thriller\n",
            "Godfather, The (1972) : Crime|Drama\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) : Action|Adventure|Sci-Fi\n",
            "Godfather: Part II, The (1974) : Crime|Drama\n",
            "Lifeboat (1944) : Drama|War\n",
            "Hustler, The (1961) : Drama\n",
            "Gallipoli (1981) : Drama|War\n",
            "Trial, The (Procès, Le) (1962) : Drama\n",
            "Gozu (Gokudô kyôfu dai-gekijô: Gozu) (2003) : Comedy|Crime|Drama|Horror|Mystery\n",
            "No Direction Home: Bob Dylan (2005) : Documentary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "at the time of writin this, the number one recommendation is my favorite movie (which I neglected to add/rate to the input sample data)\n",
        "\n",
        "a handful of my favorite movies i neglected to add/rate are consistently in the top 5 recommendations."
      ],
      "metadata": {
        "id": "UJDlH1LKdEIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 5</h1>"
      ],
      "metadata": {
        "id": "ce_TCYHcder9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding the embedded user-movie inputs.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class improvedRecommenderWithAutoEncoder(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(improvedRecommenderWithAutoEncoder, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "        self.user_movie_relationship1 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
        "        #self.user_movie_relationship2 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation= \"sigmoid\", input_shape= (50,))\n",
        "\n",
        "        self.DenseSamplerZmean = tf.keras.layers.Dense(10, name=\"z_mean\")\n",
        "        self.DenseSamplerZlogvar = tf.keras.layers.Dense(10, name=\"z_log_var\")\n",
        "        self.Sampling = Sampling()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        \n",
        "        concat_inputs = tf.concat([user_vector, movie_vector], 1)\n",
        "        concat_bias = user_bias + movie_bias\n",
        "        \n",
        "        z_mean = self.DenseSamplerZmean(concat_inputs)\n",
        "        z_log_var = self.DenseSamplerZlogvar(concat_inputs)\n",
        "        response = self.Sampling([z_mean, z_log_var])\n",
        "\n",
        "        #response = self.user_movie_relationship1(concat_inputs)\n",
        "        response = self.user_movie_relationship1(response)\n",
        "        #response = self.user_movie_relationship2(response)\n",
        "        response = response + concat_bias\n",
        "        response = self.output_layer(response)\n",
        "        return response\n",
        "    \n",
        "\n",
        "final_model = improvedRecommenderWithAutoEncoder(num_users, num_movies, EMBEDDING_SIZE)\n",
        "final_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7L0dRBudNdr",
        "outputId": "1178ad2c-5a46-4348-d1c9-ad75874464e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^complete this first"
      ],
      "metadata": {
        "id": "3Fd9L5VehPmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = final_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRhsDojrdVFD",
        "outputId": "4b66e17a-43a9-4226-e4aa-eef3d9e030ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 6s 4ms/step - loss: 0.6175 - val_loss: 0.6067\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5970 - val_loss: 0.6041\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5928 - val_loss: 0.6022\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5898 - val_loss: 0.6012\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5870 - val_loss: 0.6014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= final_model, user_id= 420)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAOSQCR5darC",
        "outputId": "1fd55ce8-55f5-4c7a-deb3-c00db232dd69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "Kolya (Kolja) (1996) : Comedy|Drama\n",
            "Lifeboat (1944) : Drama|War\n",
            "Guess Who's Coming to Dinner (1967) : Drama\n",
            "Trial, The (Procès, Le) (1962) : Drama\n",
            "Adam's Rib (1949) : Comedy|Romance\n",
            "Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997) : Action|Animation|Drama|Fantasy|Sci-Fi\n",
            "Separation, A (Jodaeiye Nader az Simin) (2011) : Drama\n",
            "Band of Brothers (2001) : Action|Drama|War\n",
            "Three Billboards Outside Ebbing, Missouri (2017) : Crime|Drama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(final_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDNGQk31dnC0",
        "outputId": "763fd673-0865-498b-a0ea-badab934f287"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Secrets & Lies (1996) : Drama\n",
            "Yojimbo (1961) : Action|Adventure\n",
            "Guess Who's Coming to Dinner (1967) : Drama\n",
            "Trial, The (Procès, Le) (1962) : Drama\n",
            "Adam's Rib (1949) : Comedy|Romance\n",
            "Bad Boy Bubby (1993) : Drama\n",
            "Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997) : Action|Animation|Drama|Fantasy|Sci-Fi\n",
            "Memories of Murder (Salinui chueok) (2003) : Crime|Drama|Mystery|Thriller\n",
            "Separation, A (Jodaeiye Nader az Simin) (2011) : Drama\n",
            "Band of Brothers (2001) : Action|Drama|War\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it usually will have one of the movies i really like that i neglected to add/rate in the top 5 (shawshank, pulp fiction, godfather, starwars, clockwork orange is usually correctly in the top 5)\n",
        "\n",
        "havent seen most of the other recommendations though, but judging by imdb pages and movie category, they are good recommendations.\n"
      ],
      "metadata": {
        "id": "Eyjqt7tnXkWC"
      }
    }
  ]
}
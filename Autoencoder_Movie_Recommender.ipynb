{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 5 - Autoencoder Movie Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimothyJan/Autoencoder-Movie-Recommender/blob/main/Autoencoder_Movie_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Project 5 - Recommendation with Autoencoders</h1>\n",
        "<p>CPSC 585<br>\n",
        "Spring 2022<br>\n",
        "Section 13883<br></p>\n",
        "\n",
        "Sean Javiya<br>\n",
        "Timothy Jan<br>\n",
        "Timothy Kheang<br>\n",
        "\n",
        "In Project 5, we apply autoencoders to the task of making movie recommendations.\n",
        "\n",
        "Goals for this project are:\n",
        "<ul>\n",
        "  <li>Examining how autoencoders can be used for recommendation.</li>\n",
        "  <li>Understanding the connection between autoencoders and embedding.</li>\n",
        "  <li>Implementing basic, deep, and variational autoencoders.</li>\n",
        "  <li>Evaluating recommender performance.</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "9V2TJ-DOiVzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 1</h1>\n",
        "<p>We began with the Keras example <a href=\"https://keras.io/examples/structured_data/collaborative_filtering_movielens/\">Collaborative Filtering for Movie Recommendations</a>.</p>\n",
        "\n",
        "<p>This example demonstrates <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">Collaborative filtering</a> using the <a href=\"https://www.kaggle.com/c/movielens-100k\">Movielens dataset</a> to recommend movies to users. The MovieLens ratings dataset lists the ratings given by a set of users to a set of movies. Our goal is to be able to predict ratings for movies a user has not yet watched. The movies with the highest predicted ratings can then be recommended to the user.</p>\n",
        "\n",
        "<p>First we download the <a href=https://www.kaggle.com/c/movielens-100k>Movielens</a> dataset, extract it, and save the CSV into <code>ratings_file</code>. It is then read into a Pandas Dataframe <code>df</code> with <code>pd.read_csv</code>.</p>"
      ],
      "metadata": {
        "id": "VvPj5B-Xi7oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwHPiMxXgrzX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "# Use the ratings.csv file\n",
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "id": "ng1PiosHj208"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Next, we do some preprocessing to encode users and movies as integer indices. We take the <code>df</code> columns <code>userId</code> and <code>movieId</code>, encode them, and save them into two new columns <code>user</code> and <code>movie</code>. <code>min_rating</code> and <code>max_rating</code> will be used to normalize the ratings later.</p>"
      ],
      "metadata": {
        "id": "zbRv2Tm4kJ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y3U0k_jkHa1",
        "outputId": "b4a851ab-755d-4dfe-d498-856975e7401f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We then prepare the training and validation data by using <code>\"user\"</code>, <code>\"movie\"</code>, <code>min_rating</code> and <code>max_rating</code>. The data is split so that 90% of the data is used for training and 10% is used for validation.</p>"
      ],
      "metadata": {
        "id": "9A1Vnf1WkShb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "metadata": {
        "id": "nyoZvZqGkQgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we create the model. We embed both users and movies into 50-dimensional vectors.</p>\n",
        "\n",
        "<p>The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias. The match score is scaled to the [0, 1] interval via a sigmoid (since our ratings are normalized to this range).</p>\n",
        "\n",
        "<p>We are using an <code>Embedding</code> layer instead of a single <code>Dense</code> hidden layer because <code>Embedding</code> layers work well with sparse data (e.g. where users have not rated most movies in the dataset).</p>\n",
        "\n",
        "<code>Embedding</code> layer turns positive integers (indexes) into dense vectors of fixed size. \n",
        "<ul>\n",
        "  <li><code>input_dim</code> is an integer that represents the size of the vocabulary. We use <code>num_users</code> and <code>num_movies</code>.</li>\n",
        "  <li><code>output_dim</code> is an integer that represents the dimension of the dense embedding. We use <code>embedding_size</code>.</li>\n",
        "  <li><code>embeddings_initializer</code> is the regularizer function applied to the embeddings matrix. We use <code>\"he_normal\"</code> initializer. It draws samples from a truncated normal distribution centered on 0 with <code>stddev = sqrt(2 / fan_in)</code> where <code>fan_in</code> is the number of input units in the weight tensor.</li>\n",
        "  <li><code>embeddings_regularizer</code> is the constraint function applied to the embeddings matrix. We use <code>keras.regularizers.l2(1e-6)</code></li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "_101bbDMkdnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "first_model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "first_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4cP5EUokXGf",
        "outputId": "4ce55a1b-ff1d-4db2-e4a2-6bfd29c03d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we fit the model to our dataset. We used a batch size of 64, 5 epochs, and a verbosity of 1 to visualize <code>loss</code> and <code>val_loss</code>. After training, we achieve a <code>loss</code> of 0.6071 and a <code>val_loss</code> of 0.6129.</p>"
      ],
      "metadata": {
        "id": "VXnLbaMSktox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = first_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI44E4LSkcVo",
        "outputId": "b3970f34-0162-406f-cd7a-cfc92d4c391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.6365 - val_loss: 0.6209\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.6135 - val_loss: 0.6168\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.6085 - val_loss: 0.6170\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 6s 4ms/step - loss: 0.6074 - val_loss: 0.6142\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.6074 - val_loss: 0.6131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We plot the training and validation loss to visualize the training process.</p>"
      ],
      "metadata": {
        "id": "PY14I6Jvk10A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4GECJpdskzxa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f7f5fc72-c27b-4d98-dea5-b9570ab52eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Now we create a function called <code>showRecommendationsUser</code> to show the top 10 movie recommendations for a given user. The input parameters are a recommender model and the specified <code>user_id</code> from the <code>df</code> Dataframe.</p>"
      ],
      "metadata": {
        "id": "j9AlMuIrmCQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showRecommendationsUser(model, user_id= df.userId.sample(1).iloc[0]):\n",
        "  movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "# Let us get a user and see the top recommendations.\n",
        "  movies_watched_by_user = df[df.userId == user_id]\n",
        "  movies_not_watched = movie_df[\n",
        "      ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "  ][\"movieId\"]\n",
        "  movies_not_watched = list(\n",
        "      set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        "  )\n",
        "  movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "  user_encoder = user2user_encoded.get(user_id)\n",
        "  user_movie_array = np.hstack(\n",
        "      ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        "  )\n",
        "  ratings = model.predict(user_movie_array).flatten()\n",
        "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "  recommended_movie_ids = [\n",
        "      movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "  ]\n",
        "  print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Movies with high ratings from user\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_user = (\n",
        "      movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "      .head(5)\n",
        "      .movieId.values\n",
        "  )\n",
        "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "  for row in movie_df_rows.itertuples():\n",
        "      print(row.title, \":\", row.genres)\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 movie recommendations\")\n",
        "  print(\"----\" * 8)\n",
        "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "  for row in recommended_movies.itertuples():\n",
        "      print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "gTtNeWMhmA4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Using our function, we show the top 10 movie recommendations for <code>user_id</code> 420 generated by our first recommender model.</p>"
      ],
      "metadata": {
        "id": "fXfo39KLKhJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= first_model, user_id= 420)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rsh2Y_kZYBc",
        "outputId": "1c847a9d-399c-4ae4-cd90-40b1667945d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) : Action|Adventure|Sci-Fi\n",
            "Princess Bride, The (1987) : Action|Adventure|Comedy|Fantasy|Romance\n",
            "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) : Action|Adventure\n",
            "Goodfellas (1990) : Crime|Drama\n",
            "Godfather: Part II, The (1974) : Crime|Drama\n",
            "Shining, The (1980) : Horror\n",
            "Stand by Me (1986) : Adventure|Drama\n",
            "Cool Hand Luke (1967) : Drama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 2</h1>\n",
        "\n",
        "<p>Now, inside of a function <code>showRecommendationsTJ()</code>, we create a feature vector for one member of our team, Timothy Jan. We pick some movies, assign a rating to each of them, and create a new Dataframe. It is then used to generate 10 movie recommendations using the recommender model passed by the input <code>model</code>.</p>"
      ],
      "metadata": {
        "id": "U4sdnup1jBwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showRecommendationsTJ(model):\n",
        "  tj_movie_ID = [121231, 122900, 122902, 122904, 122906, 122912, 122916, 122918, 122920, 122922, 125916, 128360, 131739, 134130, 134853, 140715, 140956, 159858, 161354, 161594, 162082, 163645, 164367, 166024, 166528, 167370, 168248, 168252, 168366, 174053, 174055, 176101, 177285, 177593, 177763, 177765, 179401, 179819, 180031, 180985, 182715, 183635, 184471, 185029, 185135, 185585, 187031, 187593, 189713, 188189, ]\n",
        "  tj_movie_ratings = [2.5, 3.5, 2.5, 3.75, 4.25, 4.25, 4.25, 3.5, 3.75, 3.25, 1.5, 4, 3.75, 4, 3.5, 3.75, 4, 3.75, 3.75, 4.25, 4.5, 4.25, 4.5, 4, 3.75, 0.5, 4.25, 3.5, 2, 4, 2.5, 3, 3.25, 4, 4, 3.5, 3, 3, 4.25, 3, 4, 2, 2.5, 4.5, 4.25, 4, 2.5, 3.5, 3.5, 4.5, ]\n",
        "  tj_dict = {'movieId': tj_movie_ID, 'rating':tj_movie_ratings}\n",
        "  movies_watched_by_tj = pd.DataFrame(tj_dict)\n",
        "  movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "  movies_not_watched_by_tj = movie_df[\n",
        "      ~movie_df[\"movieId\"].isin(movies_watched_by_tj.movieId.values)\n",
        "  ][\"movieId\"]\n",
        "  movies_not_watched_by_tj = list(\n",
        "      set(movies_not_watched_by_tj).intersection(set(movie2movie_encoded.keys()))\n",
        "  )\n",
        "  movies_not_watched_by_tj = [[movie2movie_encoded.get(x)] for x in movies_not_watched_by_tj]\n",
        "  user_encoder = 609 #must be in range, does not affect prediction. tested\n",
        "  user_movie_array = np.hstack(\n",
        "      ([[user_encoder]] * len(movies_not_watched_by_tj), movies_not_watched_by_tj)\n",
        "  )\n",
        "  ratings = model.predict(user_movie_array).flatten()\n",
        "  top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "  recommended_movie_ids = [\n",
        "      movie_encoded2movie.get(movies_not_watched_by_tj[x][0]) for x in top_ratings_indices\n",
        "  ]\n",
        "  print(\"Showing recommendations for user: TJ\")\n",
        "  print(\"====\" * 9)\n",
        "  print(\"Movies with high ratings from user\")\n",
        "  print(\"----\" * 8)\n",
        "  top_movies_user = (\n",
        "      movies_watched_by_tj.sort_values(by=\"rating\", ascending=False)\n",
        "      .head(5)\n",
        "      .movieId.values\n",
        "  )\n",
        "  movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "  for row in movie_df_rows.itertuples():\n",
        "      print(row.title, \":\", row.genres)\n",
        "  print(\"----\" * 8)\n",
        "  print(\"Top 10 movie recommendations\")\n",
        "  print(\"----\" * 8)\n",
        "  recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "  for row in recommended_movies.itertuples():\n",
        "      print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "diNgP--h9RlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Using our function, we show the top 10 movie recommendations for our team member generated by our first recommender model.</p>"
      ],
      "metadata": {
        "id": "_NRpuc6vlUYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(first_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z2ySvqJZ0zu",
        "outputId": "52ff437d-4a0c-4c26-bd38-a77b94f044eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
            "Shawshank Redemption, The (1994) : Crime|Drama\n",
            "Forrest Gump (1994) : Comedy|Drama|Romance|War\n",
            "Silence of the Lambs, The (1991) : Crime|Horror|Thriller\n",
            "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) : Comedy|War\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Fight Club (1999) : Action|Crime|Drama|Thriller\n",
            "Lord of the Rings: The Return of the King, The (2003) : Action|Adventure|Drama|Fantasy\n",
            "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>The results showed good recommendations and were similar to the highest-rated movies for the user.</p>"
      ],
      "metadata": {
        "id": "aAodtZHep6Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 3</h1>\n",
        "\n",
        "<p>To improve our results, we replaced the dot product with two hidden <code>Dense</code> layers in our recommender model. The first layer has 100 units, the second 50 units, and both are using the <code>relu</code> activation function.  We compiled the model using the <code>BinaryCrossentropy</code> loss function and the <code>Adam</code> optimizer with a learning rate of 0.001.</p>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "crg2CyxVi9hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class improvedRecommender(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(improvedRecommender, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "        self.user_movie_relationship1 = tf.keras.layers.Dense(100, activation= \"relu\")# use_bias= False)#, input_shape = (64,)\n",
        "        self.user_movie_relationship2 = tf.keras.layers.Dense(50, activation= \"relu\")# use_bias= False)#, input_shape = (64,)\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation= \"sigmoid\", input_shape= (50,))#, use_biase=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        \n",
        "        concat_inputs = tf.concat([user_vector, movie_vector], 1)\n",
        "        concat_bias = user_bias + movie_bias\n",
        "        response = self.user_movie_relationship1(concat_inputs)\n",
        "        response = self.user_movie_relationship2(response)\n",
        "        response = response + concat_bias\n",
        "        response = self.output_layer(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "new_model = improvedRecommender(num_users, num_movies, EMBEDDING_SIZE)\n",
        "new_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "gFcxvVMiZKEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06498015-1cce-4dee-e2c2-7c6470075f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We fit the new model to our dataset. We used a batch size of 64, 5 epochs, and a verbosity of 1. After training, we achieve a <code>loss</code> of 0.5600 and a <code>val_loss</code> of 0.6109, which is an improvement over our first model.</p>"
      ],
      "metadata": {
        "id": "N2R36mOcqUH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = new_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "id": "BlG9IdSVvcVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea6550a-cb5d-4ce1-b570-a8d0faf2cfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.6055 - val_loss: 0.6013\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5907 - val_loss: 0.6001\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5825 - val_loss: 0.6014\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5726 - val_loss: 0.6044\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5625 - val_loss: 0.6122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 4</h1>\n",
        "\n",
        "<p>Now we call our functions using our new recommender model and the same users.</p>"
      ],
      "metadata": {
        "id": "4O8JC2ss3jYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= new_model, user_id= 420)"
      ],
      "metadata": {
        "id": "x6AdaniTvdmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b25332-759d-4916-cbae-21e42bde5319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Manchurian Candidate, The (1962) : Crime|Thriller|War\n",
            "Night on Earth (1991) : Comedy|Drama\n",
            "Remember the Titans (2000) : Drama\n",
            "Last Tango in Paris (Ultimo tango a Parigi) (1972) : Drama|Romance\n",
            "Dogville (2003) : Drama|Mystery|Thriller\n",
            "Infernal Affairs (Mou gaan dou) (2002) : Crime|Drama|Thriller\n",
            "Paperman (2012) : Animation|Comedy|Romance\n",
            "Day of the Doctor, The (2013) : Adventure|Drama|Sci-Fi\n",
            "Cosmos : (no genres listed)\n",
            "Three Billboards Outside Ebbing, Missouri (2017) : Crime|Drama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgSxUQUN3XgK",
        "outputId": "51aeabb9-edbc-4c04-c7b9-570b65dce4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) : Comedy|War\n",
            "Grand Day Out with Wallace and Gromit, A (1989) : Adventure|Animation|Children|Comedy|Sci-Fi\n",
            "Thing, The (1982) : Action|Horror|Sci-Fi|Thriller\n",
            "Dog Soldiers (2002) : Action|Horror\n",
            "Magdalene Sisters, The (2002) : Drama\n",
            "Gozu (Gokudô kyôfu dai-gekijô: Gozu) (2003) : Comedy|Crime|Drama|Horror|Mystery\n",
            "Memories of Murder (Salinui chueok) (2003) : Crime|Drama|Mystery|Thriller\n",
            "Kiss Kiss Bang Bang (2005) : Comedy|Crime|Mystery|Thriller\n",
            "Dead Man's Shoes (2004) : Crime|Thriller\n",
            "FLCL (2000) : Animation|Comedy|Fantasy|Sci-Fi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of estimating the quality of the recommendations, Tim excluded some of his favorite movies from his feature vector.\n",
        "\n",
        "A handful of Tim's favorite movies that he neglected to add/rate are consistently in the top 5 recommendations. However, the overall quality of the recommendations are worse.  The previous model consistently recommended atleast 8 movies Tim enjoys."
      ],
      "metadata": {
        "id": "UJDlH1LKdEIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment 5</h1>\n",
        "\n",
        "\n",
        "<p>To improve our results farther, we added a custom<code>Sampling</code> layer in our model. After encoding our inputs in the <code>Embedding</code> layers, we invoke the <code>Sampling</code> layer. We removed the first hidden <code>Dense</code> layer with 100 units (using both layers was causing <b>mode collapse</b>) and only kept the second <code>Dense</code> with 50 units,  using the <code>relu</code> activation function.  We compiled the model using the <code>BinaryCrossentropy</code> loss function and the <code>Adam</code> optimizer with a learning rate of 0.001.</p>"
      ],
      "metadata": {
        "id": "ce_TCYHcder9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding the embedded user-movie inputs.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class improvedRecommenderWithAutoEncoder(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(improvedRecommenderWithAutoEncoder, self).__init__(**kwargs)\n",
        "        self.num_users = num_users\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "        self.user_movie_relationship1 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
        "        #self.user_movie_relationship2 = tf.keras.layers.Dense(50, activation= \"relu\")\n",
        "        self.output_layer = tf.keras.layers.Dense(1, activation= \"sigmoid\", input_shape= (50,))\n",
        "\n",
        "        self.DenseSamplerZmean = tf.keras.layers.Dense(10, name=\"z_mean\")\n",
        "        self.DenseSamplerZlogvar = tf.keras.layers.Dense(10, name=\"z_log_var\")\n",
        "        self.Sampling = Sampling()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        \n",
        "        concat_inputs = tf.concat([user_vector, movie_vector], 1)\n",
        "        concat_bias = user_bias + movie_bias\n",
        "        \n",
        "        z_mean = self.DenseSamplerZmean(concat_inputs)\n",
        "        z_log_var = self.DenseSamplerZlogvar(concat_inputs)\n",
        "        response = self.Sampling([z_mean, z_log_var])\n",
        "\n",
        "        #response = self.user_movie_relationship1(concat_inputs)\n",
        "        response = self.user_movie_relationship1(response)\n",
        "        #response = self.user_movie_relationship2(response)\n",
        "        response = response + concat_bias\n",
        "        response = self.output_layer(response)\n",
        "        return response\n",
        "    \n",
        "\n",
        "final_model = improvedRecommenderWithAutoEncoder(num_users, num_movies, EMBEDDING_SIZE)\n",
        "final_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7L0dRBudNdr",
        "outputId": "f5e1715c-e611-4423-aab4-815007070bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = final_model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRhsDojrdVFD",
        "outputId": "41a58abe-bc9b-4c2b-efca-79899e04e14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 6s 4ms/step - loss: 0.6150 - val_loss: 0.6063\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 5s 4ms/step - loss: 0.5966 - val_loss: 0.6033\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5924 - val_loss: 0.6029\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5896 - val_loss: 0.6017\n",
            "Epoch 5/5\n",
            "1418/1418 [==============================] - 5s 3ms/step - loss: 0.5874 - val_loss: 0.6027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsUser(model= final_model, user_id= 420)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAOSQCR5darC",
        "outputId": "0d081a65-0ad8-44e4-8e67-c14d2cf9ca15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: 420\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Singin' in the Rain (1952) : Comedy|Musical|Romance\n",
            "Some Like It Hot (1959) : Comedy|Crime\n",
            "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
            "Rocky Horror Picture Show, The (1975) : Comedy|Horror|Musical|Sci-Fi\n",
            "Super Size Me (2004) : Comedy|Documentary|Drama\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Rear Window (1954) : Mystery|Thriller\n",
            "Kolya (Kolja) (1996) : Comedy|Drama\n",
            "Lifeboat (1944) : Drama|War\n",
            "Woman in the Dunes (Suna no onna) (1964) : Drama\n",
            "Trial, The (Procès, Le) (1962) : Drama\n",
            "Adam's Rib (1949) : Comedy|Romance\n",
            "Jetée, La (1962) : Romance|Sci-Fi\n",
            "Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997) : Action|Animation|Drama|Fantasy|Sci-Fi\n",
            "Tekkonkinkreet (Tekkon kinkurîto) (2006) : Action|Adventure|Animation|Crime|Fantasy\n",
            "Three Billboards Outside Ebbing, Missouri (2017) : Crime|Drama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "showRecommendationsTJ(final_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDNGQk31dnC0",
        "outputId": "e6c41beb-cb4a-4729-ba7d-667ebd8d8554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing recommendations for user: TJ\n",
            "====================================\n",
            "Movies with high ratings from user\n",
            "--------------------------------\n",
            "Kingsglaive: Final Fantasy XV (2016) : Action|Adventure|Animation|Drama|Fantasy|Sci-Fi\n",
            "Train to Busan (2016) : Action|Thriller\n",
            "The Girl with All the Gifts (2016) : Drama|Horror|Sci-Fi|Thriller\n",
            "A Quiet Place (2018) : Drama|Horror|Thriller\n",
            "Sorry to Bother You (2018) : Comedy|Fantasy|Sci-Fi\n",
            "--------------------------------\n",
            "Top 10 movie recommendations\n",
            "--------------------------------\n",
            "Wallace & Gromit: The Best of Aardman Animation (1996) : Adventure|Animation|Comedy\n",
            "Secrets & Lies (1996) : Drama\n",
            "Ran (1985) : Drama|War\n",
            "Chinatown (1974) : Crime|Film-Noir|Mystery|Thriller\n",
            "Swept Away (Travolti da un insolito destino nell'azzurro mare d'Agosto) (1975) : Comedy|Drama\n",
            "Long Goodbye, The (1973) : Crime|Film-Noir\n",
            "Woman in the Dunes (Suna no onna) (1964) : Drama\n",
            "Guess Who's Coming to Dinner (1967) : Drama\n",
            "Trial, The (Procès, Le) (1962) : Drama\n",
            "There Will Be Blood (2007) : Drama|Western\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 5 recommendations will usually have one of the movies Tim really likes that he purposefully neglected to add/rate. (These correctly recommended movies include shawshank redemption, pulp fiction, godfather, starwars, clockwork orange)\n",
        "\n",
        "Tim hasn't seen most of the other recommendations though, but judging by their IMDB pages and movie category, these are good recommendations.\n",
        "\n",
        "Overall, this model is outperforming the previous model.  The quality of these recommendations is on par with the original model's recommendations.\n"
      ],
      "metadata": {
        "id": "Eyjqt7tnXkWC"
      }
    }
  ]
}
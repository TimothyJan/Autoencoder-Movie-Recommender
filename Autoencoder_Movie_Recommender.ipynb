{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 5 - Autoencoder Movie Recommender.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimothyJan/Autoencoder-Movie-Recommender/blob/main/Autoencoder_Movie_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spring 2022 - CPSC 585-section-13883\n",
        "Project 5 - Autoencoder Movie Recommender\n",
        "Sean Javiya\n",
        "Timothy Jan\n",
        "Timothy Kheang\n",
        "\n",
        "In Project 5, we apply autoencoders to the task of making movie recommendations.\n",
        "\n",
        "Goals for this project are:\n",
        "<ul>\n",
        "  <li>Examining how autoencoders can be used for recommendation.</li>\n",
        "  <li>Understanding the connection between autoencoders and embedding.</li>\n",
        "  <li>Implementing basic, deep, and variational autoencoders.</li>\n",
        "  <li>Evaluating recommender performance.</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "9V2TJ-DOiVzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We begin with the Keras example <a href=\"https://keras.io/examples/structured_data/collaborative_filtering_movielens/\">Collaborative Filtering for Movie Recommendations</a>. \n",
        "\n",
        "This example demonstrates <a href=\"https://en.wikipedia.org/wiki/Collaborative_filtering\">Collaborative filtering</a> using the <a href=\"https://www.kaggle.com/c/movielens-100k\">Movielens dataset</a> to recommend movies to users. The MovieLens ratings dataset lists the ratings given by a set of users to a set of movies. Our goal is to be able to predict ratings for movies a user has not yet watched. The movies with the highest predicted ratings can then be recommended to the user. "
      ],
      "metadata": {
        "id": "VvPj5B-Xi7oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwHPiMxXgrzX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Load the data and apply preprocessing</h1>"
      ],
      "metadata": {
        "id": "UF9lUXi0j5_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "# Use the ratings.csv file\n",
        "movielens_data_file_url = (\n",
        "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        ")\n",
        "movielens_zipped_file = keras.utils.get_file(\n",
        "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
        ")\n",
        "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
        "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
        "\n",
        "# Only extract the data the first time the script is run.\n",
        "if not movielens_dir.exists():\n",
        "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
        "        # Extract files\n",
        "        print(\"Extracting all the files now...\")\n",
        "        zip.extractall(path=keras_datasets_path)\n",
        "        print(\"Done!\")\n",
        "\n",
        "ratings_file = movielens_dir / \"ratings.csv\"\n",
        "df = pd.read_csv(ratings_file)"
      ],
      "metadata": {
        "id": "ng1PiosHj208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5115a43e-a762-4964-f5f4-c9a40b6dd581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "983040/978202 [==============================] - 0s 0us/step\n",
            "991232/978202 [==============================] - 0s 0us/step\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing to encode users and movies as integer indices."
      ],
      "metadata": {
        "id": "zbRv2Tm4kJ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "movie_ids = df[\"movieId\"].unique().tolist()\n",
        "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
        "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_movies = len(movie_encoded2movie)\n",
        "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
        "# min and max ratings will be used to normalize the ratings later\n",
        "min_rating = min(df[\"rating\"])\n",
        "max_rating = max(df[\"rating\"])\n",
        "\n",
        "print(\n",
        "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
        "        num_users, num_movies, min_rating, max_rating\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y3U0k_jkHa1",
        "outputId": "2b8b3810-6e9d-40c3-c455-817b32739c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['userId'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBveTIcKMCuw",
        "outputId": "164d7a89-3955-4a63-cb31-77e8d6e5dfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: userId, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYeMdQV-MJXo",
        "outputId": "59454e1a-f78b-4cd7-d212-fadc09c29eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Prepare training and validation data</h1>"
      ],
      "metadata": {
        "id": "9A1Vnf1WkShb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"movie\"]].values\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "# Assuming training on 90% of the data and validating on 10%.\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "x_train, x_val, y_train, y_val = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:],\n",
        ")"
      ],
      "metadata": {
        "id": "nyoZvZqGkQgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Create the model</h1>\n",
        "We embed both users and movies in to 50-dimensional vectors.<br>\n",
        "The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias. The match score is scaled to the [0, 1] interval via a sigmoid (since our ratings are normalized to this range).<br>\n",
        "We are using Embedding layer instead of a single Dense hidden layer because Embedding layers work well with sparse data(e.g. where users have not rated most movies in the dataset)"
      ],
      "metadata": {
        "id": "_101bbDMkdnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "class RecommenderNet(keras.Model):\n",
        "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
        "        super(RecommenderNet, self).__init__(**kwargs)\n",
        "        self.num_users = num_users + 1\n",
        "        self.num_movies = num_movies\n",
        "        self.embedding_size = embedding_size\n",
        "        self.user_embedding = layers.Embedding(\n",
        "            num_users+1,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.user_bias = layers.Embedding(num_users, 1)\n",
        "        self.movie_embedding = layers.Embedding(\n",
        "            num_movies,\n",
        "            embedding_size,\n",
        "            embeddings_initializer=\"he_normal\",\n",
        "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "        )\n",
        "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        user_vector = self.user_embedding(inputs[:, 0])\n",
        "        user_bias = self.user_bias(inputs[:, 0])\n",
        "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
        "        movie_bias = self.movie_bias(inputs[:, 1])\n",
        "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
        "        # Add all the components (including bias)\n",
        "        x = dot_user_movie + user_bias + movie_bias\n",
        "        # The sigmoid activation forces the rating to between 0 and 1\n",
        "        return tf.nn.sigmoid(x)\n",
        "\n",
        "\n",
        "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4cP5EUokXGf",
        "outputId": "21bf318e-392a-408f-8e2b-ad643a5474c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Train the model based on the data split</h1>"
      ],
      "metadata": {
        "id": "VXnLbaMSktox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    validation_data=(x_val, y_val),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI44E4LSkcVo",
        "outputId": "ef1b3f3e-99c5-4857-9e32-5affc43c61b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1418/1418 [==============================] - 19s 12ms/step - loss: 0.6360 - val_loss: 0.6205\n",
            "Epoch 2/5\n",
            "1418/1418 [==============================] - 15s 10ms/step - loss: 0.6136 - val_loss: 0.6160\n",
            "Epoch 3/5\n",
            "1418/1418 [==============================] - 12s 8ms/step - loss: 0.6088 - val_loss: 0.6128\n",
            "Epoch 4/5\n",
            "1418/1418 [==============================] - 10s 7ms/step - loss: 0.6070 - val_loss: 0.6124\n",
            "Epoch 5/5\n",
            "  79/1418 [>.............................] - ETA: 7s - loss: 0.6067"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Plot training and validation loss</h1>"
      ],
      "metadata": {
        "id": "PY14I6Jvk10A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4GECJpdskzxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Show top 10 movie recommendations to a user</h1>"
      ],
      "metadata": {
        "id": "j9AlMuIrmCQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
        "\n",
        "# Let us get a user and see the top recommendations.\n",
        "user_id = df.userId.sample(1).iloc[0]\n",
        "movies_watched_by_user = df[df.userId == user_id]\n",
        "movies_not_watched = movie_df[\n",
        "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
        "][\"movieId\"]\n",
        "movies_not_watched = list(\n",
        "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
        ")\n",
        "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
        "\n",
        "user_encoder = user2user_encoded.get(user_id)\n",
        "user_movie_array = np.hstack(\n",
        "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
        ")\n",
        "ratings = model.predict(user_movie_array).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "print(\"====\" * 9)\n",
        "print(\"Movies with high ratings from user\")\n",
        "print(\"----\" * 8)\n",
        "top_movies_user = (\n",
        "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "    .head(5)\n",
        "    .movieId.values\n",
        ")\n",
        "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "for row in movie_df_rows.itertuples():\n",
        "    print(row.title, \":\", row.genres)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "gTtNeWMhmA4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(user_encoder)"
      ],
      "metadata": {
        "id": "Ac2PL4ApXOJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tj_movie_ID = [121231, 122900, 122902, 122904, 122906, 122912, 122916, 122918, 122920, 122922, 125916, 128360, 131739, 134130, 134853, 140715, 140956, 159858, 161354, 161594, 162082, 163645, 164367, 166024, 166528, 167370, 168248, 168252, 168366, 174053, 174055, 176101, 177285, 177593, 177763, 177765, 179401, 179819, 180031, 180985, 182715, 183635, 184471, 185029, 185135, 185585, 187031, 187593, 189713, 188189, ]\n",
        "tj_movie_ratings = []\n",
        "movies_watched_by_tj = pd.DataFrame(tj_movie_ID, columns = ['movieId',])\n",
        "\n",
        "movies_not_watched_by_tj = movie_df[\n",
        "    ~movie_df[\"movieId\"].isin(movies_watched_by_tj.movieId.values)\n",
        "][\"movieId\"]\n",
        "movies_not_watched_by_tj = list(\n",
        "    set(movies_not_watched_by_tj).intersection(set(movie2movie_encoded.keys()))\n",
        ")\n",
        "movies_not_watched_by_tj = [[movie2movie_encoded.get(x)] for x in movies_not_watched_by_tj]\n",
        "\n",
        "# user_encoder = user2user_encoded.get(user_id)\n",
        "user_encoder = 611\n",
        "user_movie_array = np.hstack(\n",
        "    ([[user_encoder]] * len(movies_not_watched_by_tj), movies_not_watched_by_tj)\n",
        ")\n",
        "ratings = model.predict(user_movie_array).flatten()\n",
        "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "recommended_movie_ids = [\n",
        "    movie_encoded2movie.get(movies_not_watched_by_tj[x][0]) for x in top_ratings_indices\n",
        "]\n",
        "\n",
        "print(\"Showing recommendations for user: 611\")\n",
        "print(\"====\" * 9)\n",
        "# print(\"Movies with high ratings from user\")\n",
        "# print(\"----\" * 8)\n",
        "# top_movies_user = (\n",
        "#     movies_watched_by_tj.sort_values(by=\"rating\", ascending=False)\n",
        "#     .head(5)\n",
        "#     .movieId.values\n",
        "# )\n",
        "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
        "for row in movie_df_rows.itertuples():\n",
        "    print(row.title, \":\", row.genres)\n",
        "\n",
        "print(\"----\" * 8)\n",
        "print(\"Top 10 movie recommendations\")\n",
        "print(\"----\" * 8)\n",
        "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
        "for row in recommended_movies.itertuples():\n",
        "    print(row.title, \":\", row.genres)"
      ],
      "metadata": {
        "id": "diNgP--h9RlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KMzu4WGCLtZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}